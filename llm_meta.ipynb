{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d37cea3-1a8e-4366-8439-9bec25f53929",
   "metadata": {},
   "source": [
    "# ***LLM Model based on Meta***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad537c1-2f62-47f3-baa5-067c96949e9b",
   "metadata": {},
   "source": [
    "## Creating LLM model object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f39692-8898-43fc-a223-13f96754f1e4",
   "metadata": {},
   "source": [
    "GGUF and GGML are file formats used for storing models for inference, especially in the context of language models like GPT (Generative Pre-trained Transformer). GGUF was introduced as a successor to GGML format.\n",
    "\n",
    "\n",
    "A model is already downloaded and saved into working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15361d6e-2ecc-4eef-b64c-50cbf68bd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'ggml-model-q4_0.gguf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d98d72-0593-48e9-92a3-20e137a33e1d",
   "metadata": {},
   "source": [
    "Importing libraries from LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5b9d59-ed22-44a8-8460-5b8a5da05b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec293d-6986-4d9f-b228-bf208c6f803d",
   "metadata": {},
   "source": [
    "Making an object of the LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3752f03d-51d9-42ef-807c-3ba643defcfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 16 key-value pairs and 363 tensors from ggml-model-q4_0.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_0:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  7023.90 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 6016\n",
      "llama_new_context_with_model: n_batch    = 8\n",
      "llama_new_context_with_model: n_ubatch   = 8\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  4700.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 4700.00 MiB, K (f16): 2350.00 MiB, V (f16): 2350.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     8.15 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'general.file_type': '2', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '40', 'llama.attention.head_count': '40', 'llama.rope.dimension_count': '128', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.feed_forward_length': '13824', 'llama.embedding_length': '5120', 'general.name': 'LLaMA v2', 'llama.block_count': '40', 'llama.context_length': '4096', 'general.architecture': 'llama'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = LlamaCpp(model_path=llm_model_name, temperature=0.0, top_p=1, n_ctx=6000, callback_manager=callback_manager, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685621d-4cb2-4d92-9aa0-90b350a10363",
   "metadata": {},
   "source": [
    "## Asking questions to LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbaf83f-f0fa-49d3-853b-01ad87dac590",
   "metadata": {},
   "source": [
    "There are several ways to ask questions to a LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0065366-6f45-4851-bf92-6d7973f7baa6",
   "metadata": {},
   "source": [
    "#### 1st method of asking questions to a LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063572e0-a3a0-41b5-8650-12c5eba761bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/AI_LS_VirtualEnvs/Python310/VirtualEnv_LLM_Meta/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shoaib Sikander is a Pakistani cricketer who plays for the Pakistan national team. He is a right-handed batsman and a slow left-arm orthodox bowler. He made his international debut in 2015 and has since played in several Test matches, One Day Internationals (ODIs), and Twenty20 Internationals (T20Is).\n",
      "\n",
      "Sikander has had a relatively successful career so far, with some notable performances in both batting and bowling. He has scored several half-centuries and taken important wickets in crucial matches. However, he has faced stiff competition from other players in the Pakistan team and has not yet established himself as a regular member of the side.\n",
      "\n",
      "Sikander's rise to prominence in Pakistani cricket was marked by his impressive performance in the 2015-16 Quaid-e-Azam Trophy, where he scored 734 runs at an average of 52.66 and took 28 wickets at an average of 24.64. This performance earned him a call-up to the Pakistan team for"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2409.12 ms\n",
      "llama_print_timings:      sample time =      62.04 ms /   256 runs   (    0.24 ms per token,  4126.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3110.47 ms /    10 tokens (  311.05 ms per token,     3.21 tokens per second)\n",
      "llama_print_timings:        eval time =  131196.40 ms /   255 runs   (  514.50 ms per token,     1.94 tokens per second)\n",
      "llama_print_timings:       total time =  136338.96 ms /   265 tokens\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Shoaib Sikander?\"\n",
    "answer = llm(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb7d03-d9ef-48ce-a746-2e19393c4ca6",
   "metadata": {},
   "source": [
    "#### 2nd method of asking questions to a LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4752673-1aaf-4bc3-90cc-890ec880f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Shoaib Sikander is a Pakistani cricketer who plays for the Pakistan national team. He is a right-handed batsman and a slow left-arm orthodox bowler. He made his international debut in 2015 and has since played in several Test matches, One Day Internationals (ODIs), and Twenty20 Internationals (T20Is) for Pakistan.\n",
      "\n",
      "Question: What is Shoaib Sikander's highest score in Test cricket?\n",
      "\n",
      "Answer: Shoaib Sikander's highest score in Test cricket is 154 runs, which he scored against the West Indies team in the Caribbean in 2017. This innings included 18 fours and 3 sixes, and helped Pakistan to a total of 444/4 declared.\n",
      "\n",
      "Question: How many wickets has Shoaib Sikander taken in ODI cricket?\n",
      "\n",
      "Answer: In ODI cricket, Shoaib Sikander has taken 15 wickets at an average of 38.60 and an economy rate of 4.72. His"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2409.12 ms\n",
      "llama_print_timings:      sample time =      58.80 ms /   256 runs   (    0.23 ms per token,  4353.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4160.60 ms /    14 tokens (  297.19 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:        eval time =  139889.93 ms /   255 runs   (  548.59 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =  145943.12 ms /   269 tokens\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Question: Who is Shoaib Sikander?\n",
    "\"\"\"\n",
    "answer = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80513d0-fd05-47ab-9801-2a03d3aca526",
   "metadata": {},
   "source": [
    "#### 3rd method of asking questions to a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f27273-9d3a-4db6-9f92-3fb737394a99",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a29f577-6c59-4913-aa0d-a2f34e4379ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2931f-e1bd-415f-906c-b6b1d6639e37",
   "metadata": {},
   "source": [
    "Preparing a template for asking a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13831833-422c-4379-b890-aa7f0e997dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is {what}?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e931243-dd8c-4d22-bbbf-81c5a1ebe3b7",
   "metadata": {},
   "source": [
    "Creating an object of LLM chain and asking question in a format of defined template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3efad59-abf0-4cf1-97a8-08d7fe8ecebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/AI_LS_VirtualEnvs/Python310/VirtualEnv_LLM_Meta/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shoaib Sikander is a Pakistani cricketer who plays for the Pakistan national team. He is a right-handed batsman and a slow left-arm orthodox bowler. He made his international debut in 2015 and has since played in several Test matches, One Day Internationals (ODIs), and Twenty20 Internationals (T20Is).\n",
      "\n",
      "Sikander has had a relatively successful career so far, with some notable performances in both batting and bowling. He has scored several half-centuries and taken important wickets for his team. However, he has also faced criticism for his inconsistent form and lack of big scores.\n",
      "\n",
      "Overall, Shoaib Sikander is a talented cricketer who has shown promise in the international arena. He will be looking to continue his good form and cement his place in the Pakistan team for years to come."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2409.12 ms\n",
      "llama_print_timings:      sample time =      46.74 ms /   200 runs   (    0.23 ms per token,  4279.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2358.29 ms /     8 tokens (  294.79 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:        eval time =  113561.93 ms /   200 runs   (  567.81 ms per token,     1.76 tokens per second)\n",
      "llama_print_timings:       total time =  117302.86 ms /   208 tokens\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "answer = chain.run(\"Shoaib Sikander\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a3e5c9-8b9e-432f-a367-18e20539b099",
   "metadata": {},
   "source": [
    "## Updating model's knowledge base with our own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319e589-ba28-405c-885d-5ce207e7bc35",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e999d-6250-4c32-8f4f-5501b81c0be9",
   "metadata": {},
   "source": [
    "Importing libraries for loading a PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d1cac2-5f70-4cd5-b730-08604e69b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e5672-5f16-492b-acba-8aa8c1e98073",
   "metadata": {},
   "source": [
    "#### Loading PDF file containing knowledge and preparing pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c2757-f858-4607-a792-7269c07c4bf0",
   "metadata": {},
   "source": [
    "Loading PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a58483d-9f9d-4ea4-a852-b2f6ac17a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('File.pdf')\n",
    "documents = loader.load()\n",
    "#print(loader)\n",
    "#print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7856d-3bdf-4f8d-8acd-946743c100f6",
   "metadata": {},
   "source": [
    "Splitting text loaded from document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe44bfd-c312-49f0-bdcf-4dc49f05d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb973ea4-3a4e-484c-b528-03199c334208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Muhammad Shoaib Sikand er is a 32-year -old man . He belo ngs to Pakistan and currently living in \\nGermany. He  completed his bachelorâ€™s in electrical engineering  from University of The Punjab  in \\nLahore,  Pakista n and Masters in Control , Microsystem, Microelectronics from University of Bremen, \\nGermany.  Currently he is working as a Software Engineer  for AI Solutions in LS telcom  AG, Germany.', metadata={'source': 'File.pdf', 'page': 0})]\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "print(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41124ac2-9489-4aa2-bb7c-16a813d40977",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb28c4b-1350-47e2-9767-9b1d8b473a49",
   "metadata": {},
   "source": [
    "Loading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae899a69-df9e-4726-b1db-4b3ab3dcecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f703c682-5140-4395-96f2-aa003807330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/AI_LS_VirtualEnvs/Python310/VirtualEnv_LLM_Meta/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",model_kwargs={'device': 'cpu'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbe857-dde9-484d-9857-cea860e25f30",
   "metadata": {},
   "source": [
    "#### VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df099d01-893a-44ed-acd0-c452bf8a5047",
   "metadata": {},
   "source": [
    "Saving into Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a53f0b-2a9b-4e56-b9b4-4225cc5a03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727b530c-7adb-4cef-9bb9-edc43bfe33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings)\n",
    "vectordb2 = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"./abcde\")\n",
    "vectordb3 = Chroma(persist_directory=\"./abcde\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59217e-f4a6-499e-b722-084168c2bfc6",
   "metadata": {},
   "source": [
    "#### RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4046e43d-1ace-4751-8cc2-0567ce18d1ad",
   "metadata": {},
   "source": [
    "Performing Retrieval Augented Generation operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab29cf2d-b0a4-47a4-995b-9af4065fa191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19ba6999-167d-4a92-ae73-0221779e602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_updated = RetrievalQA.from_chain_type(llm, retriever=vectordb3.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0e652-d31b-4402-bf36-ef3a2f013093",
   "metadata": {},
   "source": [
    "## Asking question to updated LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee33fdd3-6f2b-4435-8bb2-5c9546838b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/AI_LS_VirtualEnvs/Python310/VirtualEnv_LLM_Meta/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided information, Shoaib Sikander is a 32-year-old man from Pakistan who currently lives in Germany and works as a Software Engineer for AI Solutions at LS telcom AG. He holds a bachelor's degree in electrical engineering from the University of The Punjab in Lahore, Pakistan, and a master's degree in control, microsystems, and microelectronics from the University of Bremen, Germany."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2409.12 ms\n",
      "llama_print_timings:      sample time =      24.10 ms /   106 runs   (    0.23 ms per token,  4398.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  168851.67 ms /   564 tokens (  299.38 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:        eval time =   50495.61 ms /   105 runs   (  480.91 ms per token,     2.08 tokens per second)\n",
      "llama_print_timings:       total time =  220233.67 ms /   669 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Who is Shoaib Sikander?\n",
      "ANSWER:  Based on the provided information, Shoaib Sikander is a 32-year-old man from Pakistan who currently lives in Germany and works as a Software Engineer for AI Solutions at LS telcom AG. He holds a bachelor's degree in electrical engineering from the University of The Punjab in Lahore, Pakistan, and a master's degree in control, microsystems, and microelectronics from the University of Bremen, Germany.\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Shoaib Sikander?\"\n",
    "\n",
    "output = llm_updated({\"query\": question})\n",
    "\n",
    "print('QUESTION: ' + output.get('query'))\n",
    "print('ANSWER: ' + output.get('result'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e17c7c-eed8-44da-af57-c305de37cdaf",
   "metadata": {},
   "source": [
    "## Useful links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d255727-ad3d-4869-9154-80a73318c586",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/llms/llamacpp/\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter/\n",
    "\n",
    "https://medium.com/@phillipgimmi/what-is-gguf-and-ggml-e364834d241c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b4849-712a-4b8a-a584-3f42508749b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348652e-bf6d-4972-9fae-6adbadece1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualEnv_LLM_Meta",
   "language": "python",
   "name": "virtualenv_llm_meta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
